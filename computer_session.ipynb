{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    !git clone https://github.com/Victor-MichelDansac/IDESSAI_2023_VMD.git\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    %cd /contents/IDESSAI_2023_VMD\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical schemes for hyperbolic equations enhanced by Scientific Machine Learning &mdash; Computer session\n",
    "\n",
    "The goals of this computer session are to:\n",
    "1. implement the necessary functions to train a PINN to approximate steady solutions to the advection equation with source term;\n",
    "2. modify the basis functions of an existing Discontinuous Galerkin code to incorporate the PINN prior.\n",
    "\n",
    "In this session, the problem under consideration is the advection equation with source term, with velocity $c = 1$:\n",
    "$$\n",
    "    \\frac{\\partial u}{\\partial t} + \\frac{\\partial u}{\\partial x} = a u + b u^2.\n",
    "$$\n",
    "The unknown function is $u : \\mathbb{R}^+ \\times \\mathbb{R} \\to \\mathbb{R}$, which depends on the time variable $t \\geq 0$ and the space variable $x$.\n",
    "\n",
    "The space domain is $x \\in (0, 1)$, and the system parameters are:\n",
    "- $a \\in (0.5, 1)$, \n",
    "- $b \\in (0.5, 1)$, \n",
    "- $u_0 \\in (0.1, 0.2)$ the left boundary condtion: $u(t, 0) = u_0$ for all $t \\geq 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports and torch setup\n",
    "# nothing to modify in this cell\n",
    "\n",
    "import os\n",
    "\n",
    "import DG_scheme\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from mesh import Mesh, run_and_plot, run_perturbation_analysis\n",
    "from model import Network\n",
    "from torch.autograd import grad\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"torch loaded; device is {device}\")\n",
    "\n",
    "torch.set_default_dtype(torch.double)\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1/ PINN training\n",
    "\n",
    "The core structure of a PINN is provided in the `model.py` file.\n",
    "Do not hesitate to check it out, but it is not mandatory for this computer session.\n",
    "\n",
    "**The goal is to implement five necessary functions**:\n",
    "1. `u_exact`: the steady solution $u_\\text{eq}$;\n",
    "2. `get_u`: the boundary ansatz $\\widetilde{W_\\theta}$;\n",
    "3. `residual`: the PDE residual $\\mathcal{N}$;\n",
    "4. `pde_loss`: the PDE loss function $\\mathcal{J}_\\text{PDE}$;\n",
    "5. `data_loss`: the data loss function $\\mathcal{J}_\\text{data}$.\n",
    "\n",
    "**Tips**:\n",
    "1. calling the model: `model(x, a, b, u0)` $ = W_\\theta(x, a, b, u_0)$;\n",
    "2. computing a gradient: `grad(y, x, torch.ones_like(x), create_graph=True)[0]` computes the gradients of $y$ with respect to $x$;\n",
    "3. all torch tensors should be at least two-dimensional (adding an empty dimension to a one-dimensional tensor can be done with `tensor[:, None]`);\n",
    "4. the model has a `random` function for uniform sampling (you can check its documentation by printing `Network.random.__doc__`);\n",
    "5. the model has a `cost_function` function to compute the loss (you can check its documentation by printing `Network.cost_function.__doc__`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_exact(x, a, b, u0):\n",
    "    \"\"\"\n",
    "    inputs: \n",
    "        x (float or tensor), \n",
    "        a (float or tensor), \n",
    "        b (float or tensor), \n",
    "        u0 (float or tensor)\n",
    "    output: exact steady solution of the advection equation with source term, same shape as x\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_u(model, x, a, b, u0):\n",
    "    \"\"\"\n",
    "    inputs: \n",
    "        model (neural network) -> W_θ,\n",
    "        x (tensor), \n",
    "        a (tensor), \n",
    "        b (tensor), \n",
    "        u0 (tensor)\n",
    "    output: approximation of the steady solution -> W_θ tilde\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def residual(model, x, a, b, u0):\n",
    "    \"\"\"\n",
    "    inputs: \n",
    "        model (neural network) -> W_θ,\n",
    "        x (tensor), \n",
    "        a (tensor), \n",
    "        b (tensor), \n",
    "        u0 (tensor)\n",
    "    output: ODE residual\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def pde_loss(model, n_collocation):\n",
    "    \"\"\"\n",
    "    inputs: \n",
    "        model (neural network) -> W_θ,\n",
    "        n_collocation (int) -> the number of collocation points\n",
    "    output: the PDE loss\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def data_loss(model, n_data):\n",
    "    \"\"\"\n",
    "    inputs: \n",
    "        model (neural network) -> W_θ,\n",
    "        n_collocation (int) -> the number of collocation points\n",
    "    output: the data loss\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "model_args = [u_exact, get_u, residual, pde_loss, data_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True  # trains the model\n",
    "# train = False  # uses the trained model (only available after training)\n",
    "\n",
    "if train:\n",
    "    new_training = False  # restarts training with the existing trained model\n",
    "    # new_training = True  # deletes the existing model and start a new training\n",
    "\n",
    "    if new_training:\n",
    "        try:\n",
    "            os.remove(Network.DEFAULT_FILE_NAME)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "    model = Network(model_args)\n",
    "\n",
    "    n_epochs = 500  # number of epochs\n",
    "    n_collocation = 10_000  # number of collocation points (for the PDE loss)\n",
    "    n_data = 0  # number of data points (for the data loss)\n",
    "    model.train(n_epochs=n_epochs, n_collocation=n_collocation, n_data=n_data)\n",
    "\n",
    "else:\n",
    "    model = Network(model_args)\n",
    "    model.plot_result(random=True, n_plots=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2/ Discontinuous Galerkin basis functions with prior\n",
    "\n",
    "Once the model has been satisfactorily trained (say, once the loss is lower than $10^{-5}$), you can add it as a prior to the DG scheme.\n",
    "\n",
    "The file `DG_scheme.py` contains the scheme, while the file `mesh.py` contains the implementation of the mesh.\n",
    "Like before, feel free to have a look around these files, but it is not mandatory.\n",
    "\n",
    "**The goal is to implement four necessary functions**:\n",
    "1. `phi_0`: first basis function;\n",
    "2. `d_phi_0`: derivative of the first basis function;\n",
    "3. `phi_k`: k<sup>th</sup> basis function, for $k \\geq 0$;\n",
    "4. `d_phi_k`: derivative of the k<sup>th</sup> basis function, for $k \\geq 0$.\n",
    "\n",
    "**Tips**:\n",
    "1. the `scheme` class, passed as input to each function, has an attribute `category`, a `str`, which controls the type of basis function:\n",
    "    1. `\"no_prior\"` corresponds to the case where no prior is applied,\n",
    "    2. the string must contain `\"with_prior\"` if a prior is applied;\n",
    "2. you can predict the value of $u$ using the function `mesh.PINN.predict_u_from_numpy` (its documentation is available by printing `Network.predict_u_from_numpy.__doc__`);\n",
    "3. you can predict the value of $\\partial_x u$ using the function `mesh.PINN.predict_dxu_from_numpy` (its documentation is available by printing `Network.predict_dxu_from_numpy.__doc__`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_0(mesh, x, x0):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        mesh (instance of the Mesh class),\n",
    "        x (numpy array),\n",
    "        x0 (numpy array)\n",
    "    output:\n",
    "        value of the first basis function at each point x\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def d_phi_0(mesh, x, x0):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        mesh (instance of the Mesh class),\n",
    "        x (numpy array),\n",
    "        x0 (numpy array)\n",
    "    output:\n",
    "        value of the derivative of the first basis function at each point x\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def phi_k(mesh, x, x0, k):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        mesh (instance of the Mesh class),\n",
    "        x (numpy array),\n",
    "        x0 (numpy array),\n",
    "        k (integer) -> the index of the basis function\n",
    "    output:\n",
    "        value of the k-th basis function at each point x\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def d_phi_k(mesh, x, x0, k):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        mesh (instance of the Mesh class),\n",
    "        x (numpy array),\n",
    "        x0 (numpy array),\n",
    "        k (integer) -> the index of the basis function\n",
    "    output:\n",
    "        value of the derivative of the k-th basis function at each point x\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "basis_functions = [phi_0, d_phi_0, phi_k, d_phi_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the basis categories you wish to test\n",
    "categories = [\n",
    "    \"no_prior\",\n",
    "    \"with_prior_additive_1\",\n",
    "    \"with_prior_additive_2\",\n",
    "    \"with_prior_multiplicative\",\n",
    "]\n",
    "\n",
    "# perturbed_initial_condition = True  # runs a perturbation analysis\n",
    "perturbed_initial_condition = False  # check the scheme output\n",
    "\n",
    "# in both cases, available optional arguments are:\n",
    "#   nx, integer, the number of space points\n",
    "#   nG, integer, the number of basis function\n",
    "#   source, bool, whether to add the source term\n",
    "#   end_time, float, the final computation time\n",
    "\n",
    "if perturbed_initial_condition:\n",
    "    run_perturbation_analysis(categories, basis_functions, model_args)\n",
    "else:\n",
    "    source = True  # approximation of a steady solution\n",
    "    # source = False  # pure advection of a Gaussian bump\n",
    "    run_and_plot(categories, basis_functions, model_args, source=source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
